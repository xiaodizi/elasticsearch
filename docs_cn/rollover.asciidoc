= 大数据量索引处理

最近看到一个问题，单个索引，6个分片。每个分片70G，这个数据量其实已经不少了。我一直认为过于庞大的数据量，无论多么牛逼的数据库进行存储，其实优化的可能性已经不大了。就得人为进行数据分割。或者冷热数据区分分离。

我以前做过财务数据，那些东西基本就是每天上千万条的流水明细，真要都放到一张表或者一个索引里边。能查的动才怪。

=== rollover

其实我第一印象对于这个问题，也是想到优化，比如filesystem cache，search after、 scroll search 。毕竟对方的第一需求是查不动了，怎么办？




=== 索引压缩


=== 索引别名
